# ğŸ¬ SubDubAI - Automatic Video Dubbing with AI

**SubDubAI** is a powerful macOS application that automatically translates videos, generates voiceovers, and creates dubbed content with time synchronization. The application uses cutting-edge AI technologies for video processing.

## âœ¨ Key Features

### ğŸ¯ Complete Video Processing Pipeline:

1. **ğŸ“¹ Audio Extraction** - Automatic audio extraction from video files
2. **ğŸ—£ï¸ Transcription** - Speech-to-text conversion with word-level accuracy
3. **ğŸŒ Translation** - Automatic text translation to target language
4. **ğŸ“ Subtitles** - Generation of synchronized subtitles (SRT, VTT, ASS)
5. **ğŸ™ï¸ Speech Synthesis** - Voiceover generation in target language
6. **ğŸ”Š Audio Assembly** - Combining voiceovers with pauses and synchronization
7. **ğŸ¬ Video Composition** - Creating final video with dubbing and subtitles

### ğŸ® User Interface:

- **Task Queue** - Manage multiple videos simultaneously
- **Progress Tracking** - Detailed information about each processing stage
- **Preset Configuration** - Language, voice, and subtitle format selection
- **Batch Processing** - Process folders with multiple videos
- **Concurrency Control** - Control number of simultaneously processed tasks

## ğŸ“¸ Screenshots

### Main Interface
![Home Screen](Screenshots/Home.png)

### Task Queue
![Queue Management](Screenshots/Queue.png)

### Settings - General
![General Settings](Screenshots/SettingsGeneral.png)

### Settings - Processing
![Processing Settings](Screenshots/SettingsProcessing.png)

## ğŸ¤– AI and APIs Used

### Core AI Services:

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Transcription** | [WhisperKit](https://github.com/argmax-ai/WhisperKit) | High-accuracy speech-to-text conversion |
| **Translation** | [macOS Translation Framework](https://developer.apple.com/documentation/translation) | Built-in text translation between languages |
| **Speech Synthesis** | [edge-tts](https://github.com/rany2/edge-tts) | Natural-sounding voiceover generation |
| **Video Processing** | [FFmpeg](https://ffmpeg.org/) | Audio extraction, assembly, and video composition |

### Supported Languages:

- English (en)
- Russian (ru)
- Spanish (es)
- French (fr)
- German (de)
- Italian (it)
- Portuguese (pt)
- Japanese (ja)
- Chinese (zh)
- And many more...

## ğŸ› ï¸ Technology Stack

### Frameworks and Libraries:

- **SwiftUI** - Modern UI framework for macOS
- **Combine** - Reactive programming
- **Swift Concurrency** - Asynchronous programming (async/await, actors)
- **Foundation** - Core APIs for file and network operations

### Architecture:

- **Clean Architecture** - Separation into Domain, Data, and Presentation layers
- **MVVM** - Model-View-ViewModel pattern for UI
- **Repository Pattern** - Data access abstraction
- **Use Cases** - Business logic layer
- **Dependency Injection** - Dependency management

### Key Components:

- **TTSService** - Voiceover generation with concurrency management
- **AudioAssemblyService** - Audio file assembly with synchronization
- **TranscriptionService** - WhisperKit integration
- **TranslationService** - Text translation
- **ShellService** - System command execution (ffmpeg, edge-tts)
- **TaskQueue** - Task queue and concurrency management

## ğŸ“‹ System Requirements

### Dependencies:

```bash
# FFmpeg - for video and audio processing
brew install ffmpeg

# edge-tts - for speech synthesis (installed automatically)
pip install edge-tts
```

### System Requirements:

- macOS 12.0 or higher
- 8 GB RAM (16 GB recommended)
- 5-10 GB free disk space (for models and cache)
- Internet connection (for initial model download)

## ğŸš€ Quick Start

### 1. Install Dependencies:

```bash
# Install FFmpeg
brew install ffmpeg

# Install edge-tts
pip install edge-tts
```

### 2. Run the Application:

```bash
# Open project in Xcode
open SubDubAI.xcodeproj

# Build and run (âŒ˜R)
```

### 3. Process Video:

1. Click "+" button to add video
2. Select video file or folder
3. Choose source and target languages
4. Select voiceover voice
5. Click "Start Processing"
6. Monitor progress in task queue

## ğŸ“ Project Structure

```
SubDubAI/
â”œâ”€â”€ SubDubAI/
â”‚   â”œâ”€â”€ Core/
â”‚   â”‚   â”œâ”€â”€ Domain/
â”‚   â”‚   â”‚   â”œâ”€â”€ Entities/          # Data models
â”‚   â”‚   â”‚   â”œâ”€â”€ Repositories/      # Repository interfaces
â”‚   â”‚   â”‚   â””â”€â”€ UseCases/          # Business logic
â”‚   â”‚   â””â”€â”€ Data/
â”‚   â”‚       â””â”€â”€ Repositories/      # Repository implementations
â”‚   â”œâ”€â”€ Features/
â”‚   â”‚   â”œâ”€â”€ Queue/                 # Task queue UI
â”‚   â”‚   â”œâ”€â”€ Settings/              # Application settings
â”‚   â”‚   â””â”€â”€ Details/               # Task details
â”‚   â”œâ”€â”€ Services/
â”‚   â”‚   â”œâ”€â”€ TTSService.swift       # Speech synthesis
â”‚   â”‚   â”œâ”€â”€ TranscriptionService.swift
â”‚   â”‚   â”œâ”€â”€ TranslationService.swift
â”‚   â”‚   â”œâ”€â”€ AudioAssemblyService.swift
â”‚   â”‚   â”œâ”€â”€ ShellService.swift
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Shared/
â”‚   â”‚   â”œâ”€â”€ State/                 # State management
â”‚   â”‚   â””â”€â”€ Extensions/            # Extensions
â”‚   â””â”€â”€ Models/
â”‚       â””â”€â”€ ...                    # Data models
â”œâ”€â”€ Input/                         # Input video files
â”œâ”€â”€ Output/                        # Processing results
â””â”€â”€ README.md
```

## âš™ï¸ Configuration

Main settings available in the application interface:

- **Max Concurrent Tasks** - System load control (1-4)
- **Source Language** - Original video language
- **Target Language** - Dubbing target language
- **TTS Voice** - Voiceover voice selection
- **Subtitle Format** - SRT, VTT, or ASS
- **Speed Sync** - Automatic voiceover speed adjustment
- **Cleanup Temp Files** - Remove intermediate files after processing

## ğŸ¯ Implementation Features

### Concurrency Management:

- **ConcurrencyLimiter** - Actor for limiting concurrent operations
- **Maximum 2 simultaneous TTS generations** - Prevents system overload
- **Per-segment timeout** - 90 seconds for voiceover generation
- **Retry with exponential backoff** - Automatic retries on errors

### Streaming Processing:

- **Real-time progress** - UI updates during processing
- **FFmpeg progress parsing** - Audio assembly progress tracking
- **Asynchronous processing** - Non-blocking operations using async/await

### Error Handling:

- **Detailed logging** - Information about each processing stage
- **Graceful degradation** - Continue on partial errors
- **Crash recovery** - Ability to restart tasks

## ğŸ“Š Performance

### Typical Processing Times (for 1-hour video):

- **Audio Extraction**: 2-5 sec
- **Transcription**: 10-30 min (depends on hardware)
- **Translation**: 1-3 min
- **Voiceover Generation**: 5-15 min
- **Audio Assembly**: 1-2 min
- **Video Composition**: 5-10 min

**Total Time**: 30-60 minutes depending on video length and computer power

## ğŸ”§ Troubleshooting

### Error: "ffmpeg not found"

```bash
brew install ffmpeg
```

### Error: "edge-tts not found"

```bash
pip install edge-tts
```

### Slow Transcription

- Close other applications to free up memory
- Use shorter videos for testing
- Verify WhisperKit model is loaded (~1.5GB)

### Translation Issues

- Check internet connection
- Verify correct languages are selected
- Restart the application

## ğŸ“ Architectural Decisions

### Swift Concurrency:

- Using `async/await` for asynchronous operations
- `Actor` for thread-safe state access
- `@MainActor` for UI updates
- `TaskGroup` for managing parallel tasks

### Reactive Programming:

- `@Published` for reactive properties
- `ObservableObject` for state management
- Combine for event processing

### Type Safety:

- Strict typing of all components
- Using `Sendable` for thread safety
- Minimizing `Any` and force unwrap usage

## ğŸ“ License

MIT License - see LICENSE file

## ğŸ¤ Contributing

Pull requests and issues are welcome!

## ğŸ“ Support

For questions and suggestions, please create an issue in the repository.

---

**Last Updated**: November 2025
